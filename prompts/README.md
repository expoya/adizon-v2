# Agent Prompts & Configuration

Dieser Ordner enth√§lt YAML-basierte Konfigurationen f√ºr alle AI-Agenten in Adizon V2.

## üìÅ Struktur

Jede YAML-Datei definiert ein vollst√§ndiges **Agent-Profil**:

- **System Prompt** - Die Pers√∂nlichkeit und Anweisungen des Agents
- **LLM Model Config** - API-Verbindung und Modell-Name
- **LLM Parameters** - Temperature, Top-P, Max-Tokens, etc.
- **Agent Settings** - Verbose, Max-Iterations, etc.
- **Metadata** - Name, Version, Changelog

## ü§ñ Verf√ºgbare Agenten

### 1. `crm_handler.yaml`
**Zweck:** Business Logic, CRM-Operationen, Tool-Calling  
**Settings:** temperature=0.4 (pr√§zise, aber kreativ genug f√ºr Probleml√∂sung)

### 2. `chat_handler.yaml`
**Zweck:** Smalltalk, Begr√º√üungen, allgemeine Konversation  
**Settings:** temperature=0.6 (nat√ºrlicher, conversational)

### 3. `intent_detection.yaml`
**Zweck:** Routing zwischen CHAT und CRM  
**Settings:** temperature=0.0 (deterministisch f√ºr konsistente Entscheidungen)

### 4. `session_guard.yaml`
**Zweck:** Entscheidet, ob Session ACTIVE (Sticky) oder IDLE bleibt  
**Settings:** temperature=0.0 (deterministisch)

## üîß Wie man Prompts bearbeitet

### 1. YAML-Datei √∂ffnen
```bash
code prompts/crm_handler.yaml
```

### 2. Prompt anpassen
```yaml
system_prompt: |
  Du bist Adizon...
  [Deine √Ñnderungen hier]
```

### 3. Parameter optimieren (optional)
```yaml
parameters:
  temperature: 0.4  # Niedriger = konsistenter, h√∂her = kreativer
  max_tokens: 500   # Maximale Antwortl√§nge
```

### 4. Speichern & Testen
Die √Ñnderungen werden **automatisch beim n√§chsten Request** geladen (Caching).

F√ºr sofortiges Reload in Development:
```python
from utils.agent_config import reload_config
reload_config("crm_handler")
```

## üé® Template-Variablen

Prompts unterst√ºtzen **dynamische Variablen**:

| Variable | Beschreibung | Beispiel |
|----------|--------------|----------|
| `{user_name}` | Name des Users | "Max" |
| `{current_date}` | Aktuelles Datum | "Monday, 2025-12-28" |
| `{user_message}` | User-Input | "Erstelle Kontakt" |
| `{last_ai_response}` | Letzte AI-Antwort | "Kontakt erstellt!" |

**Verwendung im Prompt:**
```yaml
system_prompt: |
  Du bist Adizon.
  USER: {user_name}
  DATUM: {current_date}
```

## üåç Environment Variables

Alle YAML-Files unterst√ºtzen **Environment Variable Substitution**:

```yaml
model:
  name: "${MODEL_NAME}"          # Aus .env geladen
  api_key: "${OPENROUTER_API_KEY}"
```

**Syntax:** `${VAR_NAME}` wird automatisch durch `os.getenv("VAR_NAME")` ersetzt.

## üìä Best Practices

### 1. **Versionierung**
√Ñndere die `version` und f√ºge einen Changelog-Eintrag hinzu:
```yaml
version: "2.2"
changelog:
  - "2.2: Neue Anweisungen f√ºr XYZ"
  - "2.1: Workflow-Anweisungen f√ºr Verkn√ºpfungen"
```

### 2. **A/B Testing**
Kopiere eine Config f√ºr Tests:
```bash
cp crm_handler.yaml crm_handler_v2.yaml
```

Lade im Code:
```python
config = load_agent_config("crm_handler_v2")
```

### 3. **Temperature-Guide**

| Temperature | Verhalten | Use Case |
|-------------|-----------|----------|
| 0.0 | Deterministisch | Intent Detection, Session Guard |
| 0.3-0.5 | Pr√§zise, fokussiert | CRM Operations, Tool-Calling |
| 0.6-0.8 | Nat√ºrlich, conversational | Chat, Smalltalk |
| 0.9-1.2 | Kreativ, variabel | Sales Coaching, Brainstorming |

### 4. **Prompt-L√§nge**
- **Kurz & pr√§zise** f√ºr einfache Tasks (Intent Detection)
- **Detailliert mit Beispielen** f√ºr komplexe Tasks (CRM Handler)

## üîç Debugging

### Config ausgeben
```python
from utils.agent_config import load_agent_config

config = load_agent_config("crm_handler")
print(config.get_metadata())
print(config.get_parameters())
```

### Gerenderten Prompt ansehen
```python
prompt = config.get_system_prompt(
    user_name="Test User",
    current_date="2025-12-28"
)
print(prompt)
```

## üöÄ Deployment

**Production:** Settings werden aus `.env` geladen  
**Development:** Nutze `.env.local` f√ºr lokale Overrides

**Wichtig:** Die YAML-Files selbst enthalten **keine Secrets** (nur Referenzen wie `${API_KEY}`).

## üìù Schema Reference

Vollst√§ndige YAML-Struktur:

```yaml
# Metadata
name: "Agent Name"
description: "Was macht dieser Agent?"
version: "1.0"

# LLM Configuration
model:
  name: "${MODEL_NAME}"
  base_url: "${OPENROUTER_BASE_URL}"
  api_key: "${OPENROUTER_API_KEY}"

# LLM Parameters
parameters:
  temperature: 0.4
  top_p: 0.9
  top_k: null
  max_tokens: 500
  presence_penalty: 0.0
  frequency_penalty: 0.0

# Agent Settings (optional, nur f√ºr LangChain Agents)
agent:
  verbose: true
  handle_parsing_errors: true
  max_iterations: 5

# System Prompt
system_prompt: |
  Dein Prompt hier...
  {template_var}

# Changelog
changelog:
  - "1.0: Initial Release"
```

## ü§ù Contributing

Beim √Ñndern von Prompts:
1. ‚úÖ Version hochz√§hlen
2. ‚úÖ Changelog aktualisieren
3. ‚úÖ Testen mit realen Inputs
4. ‚úÖ Git Commit mit klarer Beschreibung

---

**Letzte Aktualisierung:** 2025-12-28  
**Maintainer:** Michael & KI

